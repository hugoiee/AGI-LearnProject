{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 本地环境加载",
   "id": "eaf087e598052e8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_qwq import ChatQwen\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "load_dotenv()\n",
    "qwen_api_key = os.getenv(\"DASHSCOPE_API_KEY\")"
   ],
   "id": "94c3ffc556f65535",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 静态模型\n",
    "静态模型在创建代理时进行一次配置，并在整个执行过程中保持不变。这是最常见且最直接的方法。"
   ],
   "id": "70124ec1efd45cb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = ChatQwen(\n",
    "    model=\"qwen-flash\",\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    max_tokens=3_000,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "agent = create_agent(model)\n",
    "\n",
    "ai_msg = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"你好，你是什么模型\"\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(ai_msg[\"messages\"][-1].content)\n",
    "print(ai_msg[\"messages\"][-1].response_metadata[\"model_name\"])\n",
    "# print(ai_msg[\"messages\"][-1])"
   ],
   "id": "43b1a1ebc93cbd69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 动态模型\n",
    "动态模型的选择是在运行时环境基于当前状态以及上下文信息。这使得复杂的路由逻辑和成本优化成为可能。\n",
    "\n",
    "需要使用@wrap_model_call装饰器创建中间件，该装饰器会在请求中修改模型"
   ],
   "id": "b53d3c75f7755a67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "\n",
    "basic_model = ChatQwen(model=\"qwen-flash\", base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\", )\n",
    "advanced_model = ChatQwen(model=\"qwen-plus\", base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\", )\n",
    "\n",
    "\n",
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"根据对话的复杂程度选择合适的模型。\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "\n",
    "    if message_count > 10:\n",
    "        # 对于较长的对话，请使用高级模型。\n",
    "        model = advanced_model\n",
    "    else:\n",
    "        model = basic_model\n",
    "\n",
    "    return handler(request.override(model=model))\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,  # Default model\n",
    "    middleware=[dynamic_model_selection]\n",
    ")\n",
    "\n",
    "\n",
    "ai_msg = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"今有雉（鸡）、兔同笼，上有三十五头（总头数35），下有九十四足（总脚数94）。问雉、兔各几何？让我们一步一步思考\"\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(ai_msg[\"messages\"][-1].content)\n",
    "print(ai_msg[\"messages\"][-1].response_metadata[\"model_name\"])"
   ],
   "id": "cf5f899c05829022",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
